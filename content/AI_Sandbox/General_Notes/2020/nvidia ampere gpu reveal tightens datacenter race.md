---
title: nvidia ampere gpu reveal tightens datacenter race
tags:
  - general-note
  - hardware
  - ai
  - 2020
keywords:
  - ampere
  - nvidia
  - gpu
  - ai
draft: true
description: Nvidia unveiled Ampere architecture, doubling down on AI datacenter dominance.
created: 2020-05-14
updated: 2020-05-14
note_id: 200514GN09
cssclasses:
  - general-note
---

# nvidia ampere gpu reveal tightens datacenter race

Nvidia announced its Ampere architecture, promising over double the FP32 performance of Turing and shipping data-center cards (A100) built for AI and HPC ([Nvidia Ampere](https://www.nvidia.com/en-us/data-center/a100/)). The reveal turned compute scarcity into a strategic fight.

## scene cut
A100 uses third-generation NVLink and HBM2e, enabling huge bandwidth and multi-GPU scaling. The price bracket kept it focused on hyperscalers, leaving startups waiting.

## signal braid
- The announcement forced AMD and Intel to speed up their own accelerator roadmaps, showing compute is a geopolitical battleground like in [[nvidia export limits reshape ai hardware race]].
- Cloud providers scrambled for early reservations, echoing the frenzy we saw with [[gpu shortage hits gamers and miners]] later in the year.
- AI companies now had to budget for multi-million-dollar chip investments or risk falling behind.

## risk surface
- Delivery timelines depend on TSMC and packaging partners, so supply chain shocks can delay ramp.
- The sheer cost meant only well-capitalized players can adopt immediately.
- Demand might outstrip supply if AI workloads truly scale.

## linkage anchor
This hardware move connects to [[tesla ai day 2022 shows optimus learning curve]] because robotics needs the same compute; it also links back to [[stable diffusion release makes open source ai art mainstream]] where inference cost is still front and center.

## my take
Ampere is the compute equivalent of a navy-building spree: it signals intention and forces rivals to respond quickly.

## linkage
<div class="linkage-tree">
  <div class="linkage-tree-title">linkage tree</div>
  <ul>
    <li>tags
      <ul>
        <li>#hardware</li>
        <li>#ai</li>
        <li>#2020</li>
      </ul>
    </li>
    <li>related
      <ul>
        <li>[[nvidia export limits reshape ai hardware race]]</li>
        <li>[[stable diffusion release makes open source ai art mainstream]]</li>
      </ul>
    </li>
  </ul>
</div>

## ending questions
How much of the Ampere supply should be allocated to startups versus hyperscalers?

#
