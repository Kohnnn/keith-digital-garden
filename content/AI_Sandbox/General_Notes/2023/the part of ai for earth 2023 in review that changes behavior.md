---
title: the part of ai for earth, 2023 in review that changes behavior
tags:
  - general-note
  - ai
  - 2023
  - behavior
keywords:
  - ai
  - earth
  - 2023
  - review
  - span
draft: true
description: AI for Earth, 2023 in Review
created: 2023-12-31
updated: 2023-12-31
note_id: 231231GN33
cssclasses:
  - general-note
---

# the part of ai for earth, 2023 in review that changes behavior

<div class="inline-ref">
  <span class="inline-note">ref</span>
  <a class="ref-link external" href="https://blog.allenai.org/ai-for-earth-2023-in-review-49a27cb731a8" rel="nofollow"><span class="indicator-hook"></span>blog.allenai.org</a>
  <span class="ref-title">AI for Earth, 2023 in Review</span>
  <span class="ref-meta">2023-12-31</span>
</div>

I read ai for earth, 2023 in review as a constraint signal more than novelty. The link is just the anchor; the mechanics are where the leverage is ([source](https://blog.allenai.org/ai-for-earth-2023-in-review-49a27cb731a8)).

*see also:* [[Compute Bottlenecks]] · [[Model Behavior]]
## scene
The visible change is obvious; the deeper change is the permission it creates. I read this as a reset in expectations for teams like [[Compute Bottlenecks]] and [[Model Behavior]]. Once expectations shift, the fallback path becomes the policy.

## notes from the surface
- The way ai for earth, 2023 in review is framed compresses complexity into a single promise.
- What looks like a surface change is actually a control move.
- The dependency chain around ai for earth, 2023 in review is where risk accumulates, not at the surface.

## keep / ignore
- Signal: procurement and compliance are quietly shaping the outcome.
- Noise: demos and commentary overstate production readiness.
- Signal: incentives now favor stability over novelty.
- Noise: early excitement won’t survive the next budget cycle.

## short long
Short term, this looks like a capability win. Mid term, it becomes a budgeting and compliance question. Long term, the dominant path is whichever reduces coordination cost.

## my take
I see this as a real signal with a short half life. Move fast, but don’t calcify.

<div class="note-micro">
  <span class="inline-note">default drift</span>
  <span class="inline-note">constraint signal</span>
</div>

## linkage
<div class="linkage-tree">
  <div class="linkage-tree-title">linkage tree</div>
  <ul>
    <li>tags
      <ul>
        <li>#general-note</li>
        <li>#ai</li>
        <li>#2023</li>
      </ul>
    </li>
    <li>related
      <ul>
        <li>[[LLMs]]</li>
        <li>[[Model Behavior]]</li>
      </ul>
    </li>
  </ul>
</div>

## ending questions
If the incentives flipped, what would stay sticky?

#
