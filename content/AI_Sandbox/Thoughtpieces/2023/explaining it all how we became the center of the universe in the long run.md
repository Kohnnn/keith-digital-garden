---
title: explaining it all how we became the center of the universe in the long run
tags:
  - thoughtpiece
  - ai
  - 2023
keywords:
  - explaining
  - it
  - all
  - how
  - we
draft: true
description: Explaining It All: How We Became the Center of the Universe
created: 2023-12-30
updated: 2023-12-30
note_id: 231230TP02
cssclasses:
  - thoughtpiece
---

# explaining it all how we became the center of the universe in the long run

<div class="inline-ref">
  <span class="inline-note">ref</span>
  <a class="ref-link external" href="https://www.nytimes.com/2011/08/14/books/review/the-beginning-of-infinity-by-david-deutsch-book-review.html" rel="nofollow"><span class="indicator-hook"></span>www.nytimes.com</a>
  <span class="ref-title">Explaining It All: How We Became the Center of the Universe</span>
  <span class="ref-meta">2023-12-30</span>
</div>

I read explaining it all  how we became the center of the universe as a constraint signal more than novelty. The link is just the anchor; the mechanics are where the leverage is ([source](https://www.nytimes.com/2011/08/14/books/review/the-beginning-of-infinity-by-david-deutsch-book-review.html)).

*see also:* [[Model Behavior]] · [[LLMs]]
## set up
The visible change is obvious; the deeper change is the permission it creates. I read this as a reset in expectations for teams like [[Model Behavior]] and [[LLMs]]. Once expectations shift, the fallback path becomes the policy.

## what i see
- The first order win is clarity; the second order cost is optionality.
- The path to adopt explaining it all  how we became the center of the universe looks smooth on paper but assumes alignment that rarely exists.
- What looks like a surface change is actually a control move.

## the dominoes
policy shift -> procurement changes -> roadmap narrows
surface change -> tooling adapts -> behavior hardens
constraint tightens -> teams standardize -> defaults calcify

## exposure map
- The smallest edge case in explaining it all  how we became the center of the universe becomes the largest reputational risk.
- Governance drift turns tactical choices around explaining it all  how we became the center of the universe into strategic liabilities.
- explaining it all  how we became the center of the universe amplifies model brittleness faster than the value it returns.

## my take
I see this as a real signal with a short half life. Move fast, but don’t calcify.

<div class="note-micro">
  <span class="inline-note">default drift</span>
  <span class="inline-note">constraint signal</span>
</div>

## linkage
<div class="linkage-tree">
  <div class="linkage-tree-title">linkage tree</div>
  <ul>
    <li>tags
      <ul>
        <li>#thoughtpiece</li>
        <li>#ai</li>
        <li>#2023</li>
      </ul>
    </li>
    <li>related
      <ul>
        <li>[[LLMs]]</li>
        <li>[[Model Behavior]]</li>
      </ul>
    </li>
  </ul>
</div>

## ending questions
Which constraint would need to loosen for this to reverse?

#
